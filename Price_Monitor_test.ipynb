{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from itertools import count\n",
    "from selenium.webdriver import Chrome\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import time\n",
    "from datetime import datetime\n",
    "from multiprocessing.pool import Pool\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scraper(url_list, path):\n",
    "    global prices\n",
    "  \n",
    "    #loop through entries in list of URLs\n",
    "    for amazon_url in url_list:\n",
    "        #empty dictionary to store output\n",
    "        row_results = {}\n",
    "        row_results['scrape_time'] = str(datetime.today())\n",
    "        \n",
    "        #find product on Amazon\n",
    "        amazon_driver = Chrome(executable_path=path)\n",
    "        amazon_driver.get(amazon_url)\n",
    "        #wait for the webpage to load\n",
    "        time.sleep(5)\n",
    "\n",
    "        #grab product name from Amazon\n",
    "        try:\n",
    "            amazon_name = amazon_driver.find_element_by_xpath('//*[@id=\"productTitle\"]').text\n",
    "            row_results['amazon_name'] = amazon_name\n",
    "        except:\n",
    "            row_results['amazon_name'] = 'Item not found'\n",
    "        \n",
    "        #get Amazon price, if price is no longer available append 'Price not found'\n",
    "        try:\n",
    "            amazon_name = amazon_driver.find_element_by_xpath('//*[@id=\"priceblock_ourprice\"]').text\n",
    "            row_results['amazon_price'] = amazon_name\n",
    "        except:\n",
    "            row_results['amazon_price'] = 'Price not found'\n",
    "        \n",
    "        #get the ASIN\n",
    "        if len(amazon_url.split('/')) == 5:\n",
    "            asin = amazon_url.split('/')[4]\n",
    "        else:\n",
    "            asin = amazon_url.split('/')[5]\n",
    "        amazon_driver.quit()\n",
    "                \n",
    "        #if UPC for a specific asin has already been looked up do not look up\n",
    "        if asin in ASIN_dict:\n",
    "            upc_id = ASIN_dict[asin]\n",
    "        \n",
    "        #otherwise get UPC from ASIN\n",
    "        #note: can only look up 10 items per hour\n",
    "        else:\n",
    "            print(\"Item not found in ASIN-UPC dictionary. \\nLooking up the UPC.\")\n",
    "            upc_driver = Chrome(executable_path=path)\n",
    "            upc_driver.get('https://www.synccentric.com/features/upc-asin/')\n",
    "            box = upc_driver.find_element_by_id('scrollto')\n",
    "            form = box.find_element_by_class_name('form-group')\n",
    "            input = form.find_element_by_name('identifier')\n",
    "            input.send_keys(asin)\n",
    "            input.submit()\n",
    "            #wait for the webpage to load\n",
    "            time.sleep(10)\n",
    "            id_list = upc_driver.find_element_by_class_name('col-sm-8').find_elements_by_tag_name('strong')\n",
    "            upc_id = id_list[1].get_attribute('innerHTML')\n",
    "            upc_driver.quit()\n",
    "            #add the new asin --> upc to the dict\n",
    "            ASIN_dict[asin] = upc_id\n",
    "            \n",
    "\n",
    "        #find product on Target\n",
    "        target_driver = Chrome(executable_path=path)\n",
    "        target_url = 'https://www.target.com/s?searchTerm=' + upc_id\n",
    "        target_driver.get(target_url)\n",
    "        #wait for the webpage to load\n",
    "        time.sleep(5)\n",
    "        \n",
    "        #get Target name if the item is found on Target \n",
    "        try:\n",
    "            target_name = target_driver.find_element_by_xpath('//*[@id=\"mainContainer\"]/div[3]/div[2]/div/div[1]/div[3]/div/ul/li/div/div[2]/div/div/div/div[1]/div[1]/a').text\n",
    "            row_results['target_name'] = target_name\n",
    "        except:\n",
    "            row_results['target_name'] = \"Item not found\"\n",
    "        \n",
    "        #get Target price if item was found on Target\n",
    "        try:\n",
    "            target_price = target_driver.find_element_by_xpath('//*[@id=\"mainContainer\"]/div[3]/div[2]/div/div[1]/div[3]/div/ul/li/div/div[2]/div/div/div/div[2]/span').text\n",
    "            row_results['target_price'] = target_price\n",
    "        except:\n",
    "            row_results['target_price'] = \"Price not found\"\n",
    " \n",
    "        target_driver.quit()\n",
    "    \n",
    "\n",
    "\n",
    "        #find product on Walmart\n",
    "        walmart_driver = Chrome(executable_path=path)\n",
    "        walmart_url = 'https://www.walmart.com/search/?query=' + upc_id\n",
    "        walmart_driver.get(walmart_url)\n",
    "        \n",
    "        names_prices = walmart_driver.find_elements_by_xpath(\"//div[contains(@class, 'tile-content Grid-col u-size-8-10-l list-description-wrapper')]\")\n",
    "        \n",
    "        #get Walmart name and price if product was found on Walmart\n",
    "        if len(names_prices) == 0:\n",
    "            \n",
    "            row_results['walmart_name'] = 'Item not found'\n",
    "            row_results['walmart_price'] = 'Price not found'\n",
    "        else:\n",
    "            for i in names_prices:\n",
    "                if 'Pack' not in i.text:\n",
    "                    #if name of the product from Walmart has already been looked up do not scrape again\n",
    "                    price_list = i.text.split('\\n')\n",
    "                    row_results['walmart_name'] = price_list[price_list.index('Product Title')+1]\n",
    "                    row_results['walmart_price'] = price_list[price_list.index('Current Price')+1]\n",
    "                    \n",
    "        walmart_driver.quit()\n",
    "\n",
    "        \n",
    "        #save results at time of scrape        \n",
    "        timeofscrape = {}\n",
    "        timeofscrape['scraped_at'] = str(datetime.today())\n",
    "        timeofscrape['item'] = row_results\n",
    "        with open('price_monitor.json', 'a') as pm:\n",
    "            pm.write(','+json.dumps(timeofscrape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_top_n(search_term: str, n: int, low_price: float, high_price: float, min_reviews: int, min_rating: float):\n",
    "    '''\n",
    "    This function takes as input a search string, a number of items and a low and high value for that product.\n",
    "    Note: input search term as a space seperated string only. \n",
    "    It returns the n items that match the price criteria for the item. \n",
    "    '''\n",
    "    final_items = []\n",
    "    updated_search = search_term.replace(' ', '+')\n",
    "    for page_number in count(1):\n",
    "        if len(final_items) == n:\n",
    "            driver.close()\n",
    "            return final_items\n",
    "        if page_number >= 9:\n",
    "            print('The query has gone through 8 pages of items, but only {} have matched the criteria. The query has halted and your basket will contain this many itenms, as there are not likely to be more matches'.format(len(final_items)))\n",
    "            break\n",
    "            driver.close()\n",
    "        page = True\n",
    "        driver = webdriver.Chrome(executable_path=path)\n",
    "        search = driver.get('https://www.amazon.com/s?k={0}&page={1}&qid=1586809805&ref=sr_pg_3'.format(updated_search, page_number))\n",
    "        while page:\n",
    "            for i in count(0):\n",
    "                item = driver.find_elements_by_css_selector('div[data-index=\"{}\"]'.format(i))\n",
    "                if len(item) == 0:\n",
    "                    # go to next page and start iterator over?\n",
    "                    page = False\n",
    "                    break\n",
    "                try:\n",
    "                    price = item[0].find_element_by_class_name('a-price').text\n",
    "                    final_price = float(price.replace('$',\"\").replace('\\n', '.'))\n",
    "                except:\n",
    "                    final_price = 0\n",
    "                asin = item[0].get_attribute('data-asin')\n",
    "                if asin != '':    \n",
    "                    if final_price >= low_price:\n",
    "                        if final_price <= high_price:\n",
    "                            reviews = item[0].find_elements_by_css_selector('span[aria-label]')\n",
    "                            try:\n",
    "                                rating = float(reviews[0].get_attribute('aria-label')[:3])\n",
    "                            except:\n",
    "                                rating = 0\n",
    "                            try:\n",
    "                                num_reviews = int(reviews[1].get_attribute('aria-label').replace(',',''))\n",
    "                            except:\n",
    "                                num_reviews = 0 \n",
    "                            if num_reviews >= min_reviews:\n",
    "                                if rating >= min_rating:\n",
    "                                    url = 'https://www.amazon.com/dp/' + asin\n",
    "                                    if url not in final_items:\n",
    "                                        final_items.append(url)\n",
    "                if len(final_items) == n:\n",
    "                    driver.close()\n",
    "                    return final_items\n",
    "    return(final_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "prices = pd.DataFrame(columns=['scrape_time', 'amazon_name', 'amazon_price', 'target_name','target_price', 'walmart_name', 'walmart_price'])\n",
    "path = '/usr/local/bin/chromedriver'\n",
    " \n",
    "'''Informed Buyer'''\n",
    "#basket of items as URL\n",
    "with open('baskets/basket_list.json') as l:\n",
    "  basket_list = json.load(l)\n",
    "#basket of items as ASIN-UPC\n",
    "with open('baskets/allusers.json') as f:\n",
    "  ASIN_dict = json.load(f) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def price_scraper():\n",
    "    buyer_type = input('Are you an Informed Buyer (I) or a Window Shopper (W)? ').strip().upper()\n",
    "    '''Informed buyer'''\n",
    "    if buyer_type == 'I':\n",
    "        basket_type = input('Are you using a new list (N) or existing (E)? ').strip().upper()\n",
    "        if basket_type == 'E':\n",
    "            basket = basket_list\n",
    "        elif basket_type == 'N':\n",
    "            basket = []\n",
    "            N = int(input('How many products would you like in your basket? '))\n",
    "            for n in range(N):\n",
    "                item = input('Paste Amazon links of the product you want to track and press Enter key when done ')\n",
    "                if item == '':\n",
    "                    print('Invalid input.')\n",
    "                    return\n",
    "                else:\n",
    "                    basket.append(item)\n",
    "        #run the scraper\n",
    "        runtime = {}\n",
    "        start = time.time()\n",
    "        runtime['start_scrape'] = str(datetime.today())\n",
    "\n",
    "        #for less than 4 items in basket, run regular scraper\n",
    "        if len(basket)<4:\n",
    "            scraper(basket,path)\n",
    "        #else, run pool\n",
    "        else:\n",
    "            # Due to the particulars of pooling, we need to create a partial version of scraper that already has the path defined\n",
    "            scraper_partial = partial(scraper, path=path)\n",
    "            chunked_basket = list(chunkify(basket, 4))\n",
    "            with Pool(4) as p:\n",
    "                p.map(scraper_partial, chunked_basket)\n",
    "\n",
    "        end = time.time()\n",
    "        runs = end - start\n",
    "        runtime['runtime'] = str(runs)\n",
    "        with open('runtime.json', 'a') as rt:\n",
    "            json.dump(runtime, rt)\n",
    "            \n",
    "        # OUTPUT\n",
    "        \n",
    "            \n",
    "            \n",
    "            \n",
    "\n",
    "    elif buyer_type == 'W':\n",
    "        print('Please provide some information to narrow your search: ')\n",
    "        search_term = input('Enter a type of product you want to purchase and press Enter key when done: ')\n",
    "\n",
    "        if search_term == '':\n",
    "            print('Invalid input.')\n",
    "            return\n",
    "\n",
    "        else:\n",
    "            n = int(input('Select number of pages you would like to see and press Enter key when done: '))\n",
    "            low_price = float(input('Select lowest price and press Enter key when done: '))\n",
    "            high_price = float(input('Select highest price and press Enter key when done:'))\n",
    "            min_reviews = int(input('Select minimum number of reviews and press Enter key when done: '))\n",
    "            min_rating = float(input('Select minimum rating and press Enter key when done: '))\n",
    "            basket = find_top_n(search_term, n, low_price, high_price, min_reviews, min_rating)\n",
    "        #run the scraper\n",
    "        #for less than 4 items in basket, run regular scraper\n",
    "        if len(basket)<4:\n",
    "            scraper(basket,path)\n",
    "        #else, run pool\n",
    "        else:\n",
    "            # Due to the particulars of pooling, we need to create a partial version of scraper that already has the path defined\n",
    "            scraper_partial = partial(scraper, path=path)\n",
    "            chunked_basket = list(chunkify(basket, 4))\n",
    "            with Pool(4) as p:\n",
    "                p.map(scraper_partial, chunked_basket)\n",
    "                \n",
    "        # OUTPUT\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "amazon_name               2020-04-30 10:10:24.526087\n",
       "amazon_price     Sekiro Shadows Die Twice (Xbox One)\n",
       "target_name                          Price not found\n",
       "target_price                          Item not found\n",
       "walmart_name                         Price not found\n",
       "walmart_price                         Item not found\n",
       "what                                 Price not found\n",
       "Name: 1135, dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('price_monitor.json') as f:\n",
    "    price_tracker = json.loads(\"[\" + f.read() + \"]\")\n",
    "prices = []\n",
    "for p in price_tracker:\n",
    "    price_dict = dict(p)\n",
    "    items = price_dict['item'].values()\n",
    "    prices.append(items)\n",
    "price_df = pd.DataFrame(prices, columns=['amazon_name', 'amazon_price', 'target_name', 'target_price', 'walmart_name', 'walmart_price','what'])\n",
    "price_df.iloc[1135,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>amazon_name</th>\n",
       "      <th>amazon_price</th>\n",
       "      <th>target_name</th>\n",
       "      <th>target_price</th>\n",
       "      <th>walmart_name</th>\n",
       "      <th>walmart_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AOC C24G1 24\" Curved Frameless Gaming Monitor,...</td>\n",
       "      <td>Price not found</td>\n",
       "      <td>Item not found</td>\n",
       "      <td>Price not found</td>\n",
       "      <td>AOC C24G1 Widescreen LCD Monitor</td>\n",
       "      <td>$336.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Skytech Shiva Gaming PC Desktop - AMD Ryzen 5 ...</td>\n",
       "      <td>$1,094.00</td>\n",
       "      <td>Item not found</td>\n",
       "      <td>Price not found</td>\n",
       "      <td>Item not found</td>\n",
       "      <td>Price not found</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         amazon_name     amazon_price  \\\n",
       "0  AOC C24G1 24\" Curved Frameless Gaming Monitor,...  Price not found   \n",
       "1  Skytech Shiva Gaming PC Desktop - AMD Ryzen 5 ...        $1,094.00   \n",
       "\n",
       "      target_name     target_price                      walmart_name  \\\n",
       "0  Item not found  Price not found  AOC C24G1 Widescreen LCD Monitor   \n",
       "1  Item not found  Price not found                    Item not found   \n",
       "\n",
       "     walmart_price  \n",
       "0          $336.47  \n",
       "1  Price not found  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('price_monitor_test.json') as f:\n",
    "    price_tracker = json.loads(\"[\" + f.read() + \"]\")\n",
    "prices = []\n",
    "for p in price_tracker:\n",
    "    price_dict = dict(p)\n",
    "    scrape_time = price_dict['scraped_at']\n",
    "    items = price_dict['item'].values()\n",
    "    prices.append(items)\n",
    "price_df = pd.DataFrame(prices, columns=['amazon_name', 'amazon_price', 'target_name', 'target_price', 'walmart_name', 'walmart_price'])\n",
    "price_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[dict_values(['AOC C24G1 24\" Curved Frameless Gaming Monitor, FHD 1080p, 1500R VA panel, 1ms 144Hz, FreeSync, Height adjustable, VESA, 3-Year Zero Dead Pixels', 'Price not found', 'Item not found', 'Price not found', 'AOC C24G1 Widescreen LCD Monitor', '$336.47']),\n",
       " dict_values(['Skytech Shiva Gaming PC Desktop - AMD Ryzen 5 2600, NVIDIA RTX 2060, 16GB DDR4, 500G SSD, RGB Fans', '$1,094.00', 'Item not found', 'Price not found', 'Item not found', 'Price not found'])]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_scraper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('runtime.json') as p:\n",
    "    runtime_file = json.loads(\"[\" + p.read() + \"]\")\n",
    "runtime = []\n",
    "for d in runtime_file:\n",
    "    run_dict = dict(d)\n",
    "    runtime.append(run_dict.values())\n",
    "runtime_df = pd.DataFrame(runtime,columns=['scraped_at','runtime'])\n",
    "print(runtime_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
